{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "scilNJkjtiyr",
        "Hliqelfdtoz1"
      ],
      "mount_file_id": "1J9T9kfEM_b33PeqmLmGkD0PzRWGO2XIL",
      "authorship_tag": "ABX9TyPuXNIiepHCP1ny2AjRr11n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkami22/scraping_test/blob/main/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Googleドライブへのマウント"
      ],
      "metadata": {
        "id": "scilNJkjtiyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXrqFKYWNAIa",
        "outputId": "c6ffcca1-4345-4ddf-b7a6-3213361b28d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# アクセス可否の確認"
      ],
      "metadata": {
        "id": "Hliqelfdtoz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import urllib.robotparser\n",
        "\n",
        "# # robots.txtの読み取り\n",
        "# robots_txt_url = 'https://www.nomurakougei.co.jp/robots.txt'\n",
        "# rp = urllib.robotparser.RobotFileParser()\n",
        "# rp.set_url(robots_txt_url)\n",
        "# rp.read()\n",
        "\n",
        "# # robots.txtの情報から調査したいURL、User-Agentでクロール可能かを調べる\n",
        "# user_agent = '*'\n",
        "# url = 'https://www.nomurakougei.co.jp/achievements/*'\n",
        "# result = rp.can_fetch(user_agent, url)\n",
        "# print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY8IDwlaNINZ",
        "outputId": "3b8cf9b2-6cc8-45c4-b713-2b094c974dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# コード"
      ],
      "metadata": {
        "id": "2IITqqNiuKwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前設定"
      ],
      "metadata": {
        "id": "UuvucknNQu2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要ライブラリのインポート\n",
        "import urllib\n",
        "from urllib.error import URLError\n",
        "from requests.models import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# デバッグ用\n",
        "import sys\n",
        "import pprint"
      ],
      "metadata": {
        "id": "h6eCW0CUOa7l"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soupを作成する関数\n",
        "def MakeSoup(url, ua):\n",
        "  req = urllib.request.Request(url, headers={'User-Agent': ua})\n",
        "  try:\n",
        "    html = urllib.request.urlopen(req)\n",
        "  except HTTPError as e:\n",
        "    print('HTTPError')\n",
        "  except URLError as e:\n",
        "    print('URLError')\n",
        "  else:\n",
        "    if not html.geturl() == url:\n",
        "      print('Redirected')\n",
        "    else:\n",
        "      return BeautifulSoup(html, \"html.parser\")"
      ],
      "metadata": {
        "id": "q626M8UZNSPq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# トップページURL\n",
        "url_root = 'https://www.nomurakougei.co.jp'\n",
        "# ユーザーエージェント\n",
        "ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'"
      ],
      "metadata": {
        "id": "ODLE5LWQQDJ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [すべての実績一覧](https://www.nomurakougei.co.jp/achievements/all)"
      ],
      "metadata": {
        "id": "nprns3adQfuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# すべての実績一覧 ページURLを全て取得する関数\n",
        "def Get_AchievementsAll_PageUrl_list(url_root):\n",
        "  url_achievementsAll = url_root + '/achievements/all'\n",
        "  url_achievementsPages_list = []\n",
        "  i = 1\n",
        "  while True:\n",
        "    i_url_achievements = url_achievementsAll + f'?page={i}'\n",
        "    i_soup_achievements = MakeSoup(i_url_achievements, ua)\n",
        "    if not i_soup_achievements is None:\n",
        "      url_achievementsPages_list.append(i_url_achievements)\n",
        "      i += 1\n",
        "    else:\n",
        "      break\n",
        "  return url_achievementsPages_list"
      ],
      "metadata": {
        "id": "9xvCJH42cVqN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ページリンクを取得\n",
        "url_achievementsPages_list = Get_AchievementsAll_PageUrl_list(url_root)\n",
        "# 個別実績タイトル、リンクを全て取得\n",
        "title_achievement_list = []\n",
        "url_achievement_list = []\n",
        "for page_num, url_achievementsPage in enumerate(url_achievementsPages_list):\n",
        "  soup_achievementsPage = MakeSoup(url_achievementsPage, ua)\n",
        "  ul_a_list = soup_achievementsPage.article.find('ul', {\"class\": \"wall col-3\"}).find_all(\"a\")\n",
        "  for i_ul_a in ul_a_list:\n",
        "    i_ul_title = i_ul_a.get('title')\n",
        "    i_ul_href = i_ul_a.get('href')\n",
        "    title_achievement_list.append(i_ul_title)\n",
        "    url_achievement_list.append(url_root + i_ul_href)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeGp-ALcOm-F",
        "outputId": "32bb824b-4c7a-4757-ecf5-67b0159a2821"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redirected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 個別実績"
      ],
      "metadata": {
        "id": "--i-mAbDhm2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 個別実績タイトル、リンクのリスト\n",
        "# title_achievement_list = []\n",
        "# url_achievement_list = []\n",
        "\n",
        "# 個別実績ページ\n",
        "# 全ての施工情報タイトル\n",
        "title_constraction_list = ['オープン', '所在地', 'クライアント', '業務内容', '受賞']\n",
        "# title_constraction_list = []\n",
        "\n",
        "# 保存用dictのlist\n",
        "savedict_list = []\n",
        "for i, (title_achievement, url_achievement) in enumerate(zip(title_achievement_list, url_achievement_list)):\n",
        "  soup_achievement = MakeSoup(url_achievement, ua)\n",
        "\n",
        "  # キーワードの取得\n",
        "  tag_ul = soup_achievement.article.ul\n",
        "  # キーワード設定の有無を確認\n",
        "  keyword_achievement_list = []\n",
        "  if not tag_ul is None:\n",
        "    i_a_list = tag_ul.find_all(\"a\", {\"class\": \"link link-c\"})\n",
        "    for j_a in i_a_list:\n",
        "      j_title = j_a.get('title')\n",
        "      keyword_achievement_list.append(j_title)\n",
        "\n",
        "  \"\"\"\n",
        "  施工情報については\"dl\"タグ内の、\"dd\"タグにタイトル、\"dt\"に施工データ が書かれているが、\n",
        "  全ての閉じタグが最後にまとめて記述されているため、BeautifulSoupのメソッドでは対処できない\n",
        "  そこで、文字列に変換してから区切ることで該当情報を抽出する\n",
        "  \"\"\"\n",
        "  # 施工情報の取得\n",
        "  tag_dl = soup_achievement.article.find(\"dl\", {\"class\": \"list-b\"})\n",
        "  # 施工情報設定の有無を確認\n",
        "  infoKey_achPage_list = []\n",
        "  infoValue_achPage_list = []\n",
        "  if not tag_dl is None:\n",
        "    # タイトルの取得\n",
        "    i_list_dt = tag_dl.find_all(\"dt\")\n",
        "    i_title_list = []\n",
        "    for j_list_dt in i_list_dt:\n",
        "      # 文字列化し、先頭の不要な文字列(改行、空白等)を削除\n",
        "      j_list_dt_text = j_list_dt.text.lstrip()\n",
        "      # 区切り文字(\"：\")の位置を探し、それ以前の文字列を取得する\n",
        "      j_dt_delimiter = j_list_dt_text.find(\"：\")\n",
        "      j_title = j_list_dt_text[: j_dt_delimiter]\n",
        "      i_title_list.append(j_title)\n",
        "\n",
        "    # 施工データのリスト取得\n",
        "    i_list_dd = tag_dl.find_all(\"dd\")\n",
        "    i_data_list = []\n",
        "    for j_list_dd in i_list_dd:\n",
        "      # 文字列化し、先頭の不要な文字列(改行、空白等)を削除\n",
        "      j_list_dd_text = j_list_dd.text.lstrip()\n",
        "      # 区切り文字(\"\\n\")の位置を探し、それ以前の文字列を取得する\n",
        "      j_dd_delimiter = j_list_dd_text.find(\"\\n\")\n",
        "      j_data = j_list_dd_text[: j_dd_delimiter]\n",
        "      # 末尾の不要な文字列を削除する\n",
        "      j_data = j_data.rstrip()\n",
        "      i_data_list.append(j_data)\n",
        "\n",
        "    # # 全ての施工情報タイトルに不足分を追加\n",
        "    # if set(i_title_list) - set(title_constraction_list):\n",
        "    #   for j_title in i_title_list:\n",
        "    #     if j_title not in title_constraction_list:\n",
        "    #       title_constraction_list.append(j_title)\n",
        "\n",
        "  # 個別実績の保存\n",
        "  savedict = {\"タイトル\": title_achievement,\n",
        "              \"URL\": url_achievement,\n",
        "              \"キーワード\": \",\".join(keyword_achievement_list)}\n",
        "  # 掲載されいている施工情報を保存\n",
        "  for (j_title, j_data) in zip(i_title_list, i_data_list):\n",
        "    savedict[j_title] = j_data\n",
        "  # i_title_list_none = list(set(title_constraction_list) - set(i_title_list))\n",
        "  # if i_title_list_none:\n",
        "  #   for j_title_none in i_title_list_none:\n",
        "  #     savedict[j_title_none] = \"\"\n",
        "  savedict_list.append(savedict)"
      ],
      "metadata": {
        "id": "oW9Iv_ziP9D2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保存"
      ],
      "metadata": {
        "id": "zWIgyCQ2LM7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# savedict_listをcsvで出力\n",
        "keylist = ['タイトル', 'URL', 'キーワード', 'オープン', '所在地', 'クライアント', '業務内容', '受賞']\n",
        "with open(\"乃村工藝社/scraping_result_all.csv\", \"w\") as f:\n",
        "    writer = csv.DictWriter(f, keylist)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(savedict_list)"
      ],
      "metadata": {
        "id": "EmBacTFSEUUR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## テスト"
      ],
      "metadata": {
        "id": "sNdszhpvuPRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(savedict_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvSaQKFYXK7A",
        "outputId": "939126cf-01d8-4534-c403-baf071a98da6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'URL': 'https://www.nomurakougei.co.jp/achievements/page/the-base-sports-bike-and-community',\n",
            "  'オープン': '2021年',\n",
            "  'キーワード': ['ニューノーマル'],\n",
            "  'クライアント': '株式会社あさひ様',\n",
            "  'タイトル': 'THE BASE SPORTS BIKE & COMMUNITY',\n",
            "  '受賞': '',\n",
            "  '所在地': '東京都',\n",
            "  '業務内容': 'デザイン・設計、制作・内装施工'},\n",
            " {'URL': 'https://www.nomurakougei.co.jp/achievements/page/kyushu-mitsubishi-motors-kmg-building',\n",
            "  'オープン': '2021年',\n",
            "  'キーワード': ['デジタル', 'ワークプレイス', 'SDGs'],\n",
            "  'クライアント': '九州三菱自動車販売株式会社様',\n",
            "  'タイトル': '九州三菱自動車販売株式会社 KMGビル',\n",
            "  '受賞': '',\n",
            "  '所在地': '福岡県',\n",
            "  '業務内容': 'デザイン・設計、サイン・グラフィックデザイン、デザイン監修、内装監理、環境演出装置設計・制作、制作・内装施工'},\n",
            " {'URL': 'https://www.nomurakougei.co.jp/achievements/page/nagasaki-kaidou-kamome-ichiba',\n",
            "  'オープン': '2022年',\n",
            "  'キーワード': ['地域創生・エリアブランディング', '観光'],\n",
            "  'クライアント': '九州旅客鉄道株式会社様、株式会社JR長崎シティ様',\n",
            "  'タイトル': '長崎街道かもめ市場',\n",
            "  '受賞': '「NAGOYA MOSAIC-TILE DESIGN AWARD 2022」銀賞〈非住宅部門〉',\n",
            "  '所在地': '長崎県',\n",
            "  '業務内容': 'デザイン・設計、環境デザイン、デザイン監修、什器制作'},\n",
            " {'URL': 'https://www.nomurakougei.co.jp/achievements/page/jre-kanda-ogawamachi',\n",
            "  'オープン': '2022年',\n",
            "  'キーワード': ['ワークプレイス', 'SDGs'],\n",
            "  'クライアント': 'ジャパンリアルエステイト投資法人様',\n",
            "  'タイトル': 'JRE神田小川町ビル',\n",
            "  '受賞': '',\n",
            "  '所在地': '東京都',\n",
            "  '業務内容': 'デザイン・設計、サイン・グラフィックデザイン、デザイン監修、制作・内装施工'}]\n"
          ]
        }
      ]
    }
  ]
}